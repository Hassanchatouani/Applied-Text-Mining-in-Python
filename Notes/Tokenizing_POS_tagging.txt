Basic NLP Tasks with NLTK

import nltk
from nltk.book import *

#----------------------------------------------------------
# Counting vocabulary of words
text7
sent7
len(sent7)
len(text7)
list(set(text7))[:10]


#----------------------------------------------------------
# Frequency of words

dist = FreqDist(text7)
len(dist) # set of unique words = list(set(text7))

vocab1 = dist.keys()
#vocab1[:10] 
# In Python 3 dict.keys() returns an iterable view instead of a list
list(vocab1)[:10] # first 10 unique words

freqwords = [w for w in vocab1 if len(w) > 5 and dist[w] > 100]
freqwords

dist = nltk.FreqDist(tot)
dist.most_common(20)


#----------------------------------------------------------
# Normalization and stemming
# This is to identify the words that have the same meaning

input1 = "List listed lists listing listings"
words1 = input1.lower().split(' ')
words1

porter = nltk.PorterStemmer()
[porter.stem(t) for t in words1] # will output ['list', 'list', 'list', 'list', 'list']
# this shows that "List listed lists listing listings" all have the same meanings

#----------------------------------------------------------
# Lemmatization
# is a process of picking out words that are meaningful. Changing each word into its meaningful form
# e.g. changing declaration to declar. Universal to Universe
 
udhr = nltk.corpus.udhr.words('English-Latin1')
udhr[:20]
[porter.stem(t) for t in udhr[:20]] # A method of Lemmatization/Stemming. But the resulting words maynot be valid words.

WNlemma = nltk.WordNetLemmatizer()
[WNlemma.lemmatize(t) for t in udhr[:20]]   # A method of Lemmatization. The resulting words will be valid words.




#----------------------------------------------------------
# Tokenization
# is a process where we split out the sentence into words/tokens

# originally we use the .split(" ") to split the sentence
text11 = "Children shouldn't drink a sugary drink before bed."
text11.split(' ')   #['Children', "shouldn't", 'drink', 'a', 'sugary', 'drink', 'before', 'bed.']
# but the output "bed." has full stop with it. Not a valid word
# hence we want to use nltk.word_tokenize function


# word tokenizer 
nltk.word_tokenize(text11)
['Children', 'should',  "n't", 'drink', 'a', 'sugary', 'drink', 'before', 'bed', '.']


# Sentence tokenizer
# not all full stops or punctuations are the end of sentence. Not trivial task! e.g. U.S.
text12 = "This is the first sentence. A gallon of milk in the U.S. costs $2.99. Is this the third sentence? Yes, it is!"
sentences = nltk.sent_tokenize(text12)
len(sentences) # 4



#----------------------------------------------------------
# Advanced NLP Tasks with NLTK

# POS tagging
# To identify which words falls into which category
# CC Conjunction, CD Cardinal, DT Determiner, IN Preposition, JJ Adjective, MD Model, NN Noun, POS Possessive, PRP Pronoun
# RB Adverb, SYM Symbol, VB Verb

nltk.help.upenn_tagset('MD')

text14 = nltk.word_tokenize("Visiting aunts can be a nuisance")
nltk.pos_tag(text14)
# Output

[('Visiting', 'VBG'),
 ('aunts', 'NNS'),
 ('can', 'MD'),
 ('be', 'VB'),
 ('a', 'DT'),
 ('nuisance', 'NN')]

#----------------------------------------------------------------
# Parsing sentence structure
text15 = nltk.word_tokenize("Alice loves Bob")
grammar = nltk.CFG.fromstring("""
S -> NP VP
VP -> V NP
NP -> 'Alice' | 'Bob'
V -> 'loves'
""")

parser = nltk.ChartParser(grammar)
trees = parser.parse_all(text15)
for tree in trees:
    print(tree)

text16 = nltk.word_tokenize("I saw the man with a telescope")
grammar1 = nltk.data.load('mygrammar.cfg')
grammar1

parser = nltk.ChartParser(grammar1)
trees = parser.parse_all(text16)
for tree in trees:
    print(tree)


from nltk.corpus import treebank
text17 = treebank.parsed_sents('wsj_0001.mrg')[0]
print(text17)


# POS tagging and parsing ambiguity
text18 = nltk.word_tokenize("The old man the boat")
nltk.pos_tag(text18)
# Output
# [('The', 'DT'), ('old', 'JJ'), ('man', 'NN'), ('the', 'DT'), ('boat', 'NN')]
# Sometimes the sentence doesnt make sense even though the structure is correct
text19 = nltk.word_tokenize("Colorless green ideas sleep furiously")
nltk.pos_tag(text19)
# Output
# [('Colorless', 'NNP'), ('green', 'JJ'), ('ideas', 'NNS'),  ('sleep', 'VBP'), ('furiously', 'RB')]
